# -*- coding: utf-8 -*-
"""Consumer_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hR0hLEytyq_XsQHQemYIr3hCB5G7-rRB
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, confusion_matrix, roc_curve, auc)
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/consumer_classification_dataset.csv')

"""Dataset Description and Exploration"""

print("Dataset Shape:", df.shape)
print("Number of features:", (df.shape[1])-1)

print("\nDataset Info:")
print(df.info())

print("\nMissing Values:")
print(df.isnull().sum())
print("\nTarget Variable Distribution:")
print(df['Churn'].value_counts())

# Identify numerical and categorical features
numerical_features = df.select_dtypes(include=np.number).columns
categorical_features = df.select_dtypes(include='object').columns

print(f"Number of numerical features: {len(numerical_features)}")
print(f"Number of categorical features: {len(categorical_features)}")

df[numerical_features].hist(figsize=(12,12),bins=20)
plt.show()

# categorical features
for feature in categorical_features:
    plt.figure(figsize=(8, 6))
    sns.countplot(x=feature, hue='Churn', data=df)
    plt.title(f'Distribution of {feature} by Churn')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# Explore relationship between numerical features and target variable
numerical_features_with_target = numerical_features.tolist()
numerical_features_with_target.append('Churn')

for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='Churn', y=feature, data=df)
    plt.title(f'{feature} vs. Churn')
    plt.tight_layout()
    plt.show()

"""Data Preprocessing"""

df_processed = df.copy()

# missing values and median imputation

num_imputer = SimpleImputer(strategy='median')
numerical_cols = ['Age', 'Income', 'Credit_Score']
df_processed[numerical_cols] = num_imputer.fit_transform(df_processed[numerical_cols])

# mode imputation
cat_imputer = SimpleImputer(strategy='most_frequent')
categorical_cols = ['Gender', 'Marital_Status']
df_processed[categorical_cols] = cat_imputer.fit_transform(df_processed[categorical_cols])

# Encode categorical variables
label_encoders = {}
categorical_features = ['Gender', 'Marital_Status', 'Device_Used']
for feature in categorical_features:
    le = LabelEncoder()
    df_processed[feature] = le.fit_transform(df_processed[feature].astype(str))
    label_encoders[feature] = le

# Feature Engineering
df_processed['Income_Age_Ratio'] = df_processed['Income'] / (df_processed['Age'] + 1)
df_processed['Purchase_Frequency'] = df_processed['Num_Purchases'] / (df_processed['Membership_Years'] + 1)

"""Feature scaling"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Convert back to DataFrame for easy reference
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

row_index = 0
print("Original Values:")
for col in X.columns:
    print(f"{col}: {X.iloc[row_index][col]}")

print("\nScaled Values:")
for col in X.columns:
    print(f"{col}: {X_scaled_df.iloc[row_index][col]:.4f}")

# Separate features and target
X = df_processed.drop('Churn', axis=1)
y = df_processed['Churn']

"""Dataset Splitting"""

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42, stratify=y
)

print(f"Training set size: {X_train.shape[0]}")
print(f"Test set size: {X_test.shape[0]}")

# Display correlation heatmap
plt.figure(figsize=(12, 8))
corr_matrix = df_processed.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

#KNN, Logistic regression and neural network model training
models = {
    'KNN': KNeighborsClassifier(),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=100),
    'Neural Network': MLPClassifier(random_state=42, max_iter=1000, hidden_layer_sizes=(100, 50))
}

# Train and evaluate models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)

    #predictions
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)


    results[name] = {
        'model': model,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba
    }

    print(f"{name}:")
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    print(f"  F1-Score: {f1:.4f}")
    print("-" * 50)

#Model Comparison and Visualization
metrics_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Accuracy': [results[m]['accuracy'] for m in results],
    'Precision': [results[m]['precision'] for m in results],
    'Recall': [results[m]['recall'] for m in results],
    'F1-Score': [results[m]['f1'] for m in results]
})

#accuracy comparison
plt.figure(figsize=(10, 6))
metrics_df.set_index('Model')['Accuracy'].plot(kind='bar')
plt.title('Model Accuracy Comparison (KNN, Logistic Regression, Neural Network)')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('selected_models_accuracy_comparison.png')
plt.show()

#precision, recall, and F1-score
metrics_df.set_index('Model')[['Precision', 'Recall', 'F1-Score']].plot(kind='bar', figsize=(12, 6))
plt.title('Model Precision, Recall, and F1-Score Comparison')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('selected_models_precision_recall_f1_comparison.png')
plt.show()

# Confusion matrices
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
axes = axes.ravel()

for i, (name, result) in enumerate(results.items()):
    cm = confusion_matrix(y_test, result['y_pred'])
    sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')
    axes[i].set_title(f'{name} Confusion Matrix')
    axes[i].set_xlabel('Predicted')
    axes[i].set_ylabel('Actual')

plt.tight_layout()
plt.savefig('selected_models_confusion_matrices.png')
plt.show()

# ROC curves
plt.figure(figsize=(10, 8))
for name, result in results.items():
    if result['y_pred_proba'] is not None:
        fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Selected Models')
plt.legend(loc="lower right")
plt.savefig('selected_models_roc_curves.png')
plt.show()

#unsupervised k-means

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

#K-Means clustering
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_scaled)

df_processed['Cluster'] = clusters

# Reduce dimensionality for visualization using PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Add PCA components to the processed dataframe
df_processed['PCA1'] = X_pca[:, 0]
df_processed['PCA2'] = X_pca[:, 1]

plt.figure(figsize=(10, 8))
sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df_processed, palette='viridis', s=100)
plt.title('K-Means Clustering Results (PCA Reduced)')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()

print("\nCluster distribution:")
print(df_processed['Cluster'].value_counts())